{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "# # Spam classification\n",
    "\n",
    "# ## Import libraries\n",
    "\n",
    "# In[5]:\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import collections\n",
    "import re\n",
    "import random\n",
    "import scipy.io\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pandas_ml import ConfusionMatrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.metrics import precision_score, \\\n",
    "    recall_score, confusion_matrix, classification_report, \\\n",
    "    accuracy_score, f1_score\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from nltk import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#setting the path for the location\n",
    "import os\n",
    "os.chdir('D:/Freelancer_questions/Spam_ham/Enron-Email-Classification-master/Enron-Email-Classification-master')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ## Vectorizer\n",
    "#reading the input data from the txt spam vs ham file\n",
    "# In[8]:\n",
    "\n",
    "NUM_TRAINING_EXAMPLES = 5172\n",
    "NUM_TEST_EXAMPLES = 5857\n",
    "\n",
    "BASE_DIR = './'\n",
    "SPAM_DIR = 'spam/'\n",
    "HAM_DIR = 'ham/'\n",
    "TEST_DIR = 'test/'\n",
    "\n",
    "vectorizer = TfidfVectorizer(input='filename',lowercase=True, stop_words=\"english\",\n",
    "                             encoding='latin-1',min_df=8) \n",
    "\n",
    "spam_filenames = glob.glob( BASE_DIR + SPAM_DIR + '*.txt')\n",
    "ham_filenames = glob.glob( BASE_DIR + HAM_DIR + '*.txt')\n",
    "test_filenames = [BASE_DIR + TEST_DIR + str(x) + '.txt' for x in range(NUM_TEST_EXAMPLES)]\n",
    "all_filenames = spam_filenames + ham_filenames # including test_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converted the data to countvectorizer and created a dictionary on the same#\n",
    "train_matrix = vectorizer.fit_transform(all_filenames)\n",
    "test_matrix = vectorizer.transform(test_filenames)\n",
    "X = train_matrix\n",
    "Y = [1]*len(spam_filenames) + [0]*len(ham_filenames)\n",
    "\n",
    "# Save as .mat \n",
    "file_dict = {}\n",
    "file_dict['training_data'] = X\n",
    "file_dict['training_labels'] = Y\n",
    "file_dict['test_data'] = test_matrix\n",
    "scipy.io.savemat('email_data.mat', file_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        ...,\n",
       "        [0.        , 0.        , 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.03169233, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ],\n",
       "        [0.        , 0.03007344, 0.        , ..., 0.        , 0.        ,\n",
       "         0.        ]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the dictionary sample\n",
    "file_dict['training_data'].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ragha\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "train_X = data['training_data'].toarray()\n",
    "train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "test_X = data['test_data'].toarray()\n",
    "dt = DecisionTreeClassifier() \n",
    "    \n",
    "clf = AdaBoostClassifier(n_estimators=50, base_estimator=dt,learning_rate=1).fit(X_train, y_train)\n",
    "predicted_test = clf.predict(test_X)\n",
    "predicted_val = clf.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9642512077294686\n",
      "F1 score: 0.9417322834645668\n",
      "Recall: 0.9492063492063492\n",
      "Precision: 0.934375\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       720\n",
      "           1       0.93      0.95      0.94       315\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1035\n",
      "   macro avg       0.96      0.96      0.96      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[699  21]\n",
      " [ 16 299]]\n"
     ]
    }
   ],
   "source": [
    "data = scipy.io.loadmat('./email_data.mat')\n",
    "def adaboost_submission(data):\n",
    "    # combine test and training data for scaling\n",
    "    \n",
    "    train_X = data['training_data'].toarray()\n",
    "    train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "    test_X = data['test_data'].toarray()\n",
    "    dt = DecisionTreeClassifier() \n",
    "    \n",
    "    clf = AdaBoostClassifier(n_estimators=50, base_estimator=dt,learning_rate=1).fit(X_train, y_train)\n",
    "    predicted_test = clf.predict(test_X)\n",
    "    predicted_val = clf.predict(X_val)\n",
    " \n",
    "\n",
    "    print ('Accuracy:', accuracy_score(y_val, predicted_val))\n",
    "    print ('F1 score:', f1_score(y_val, predicted_val))\n",
    "    print ('Recall:', recall_score(y_val, predicted_val))\n",
    "    print ('Precision:', precision_score(y_val, predicted_val))\n",
    "    print ('\\n clasification report:\\n', classification_report(y_val, predicted_val))\n",
    "    print ('\\n confussion matrix:\\n',confusion_matrix(y_val, predicted_val))\n",
    "    \n",
    "    return predicted_test\n",
    "\n",
    "submit_ada = adaboost_submission(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8830917874396135\n",
      "F1 score: 0.7979966611018363\n",
      "Recall: 0.7587301587301587\n",
      "Precision: 0.8415492957746479\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92       720\n",
      "           1       0.84      0.76      0.80       315\n",
      "\n",
      "   micro avg       0.88      0.88      0.88      1035\n",
      "   macro avg       0.87      0.85      0.86      1035\n",
      "weighted avg       0.88      0.88      0.88      1035\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[675  45]\n",
      " [ 76 239]]\n"
     ]
    }
   ],
   "source": [
    "def lda_submission(data):\n",
    "    # combine test and training data for scaling\n",
    "    train_X = data['training_data'].toarray()\n",
    "    train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "    test_X = data['test_data'].toarray()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "    clf = LinearDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    predicted_test = clf.predict(test_X)\n",
    "    predicted_val = clf.predict(X_val)\n",
    " \n",
    "\n",
    "    print ('Accuracy:', accuracy_score(y_val, predicted_val))\n",
    "    print ('F1 score:', f1_score(y_val, predicted_val))\n",
    "    print ('Recall:', recall_score(y_val, predicted_val))\n",
    "    print ('Precision:', precision_score(y_val, predicted_val))\n",
    "    print ('\\n clasification report:\\n', classification_report(y_val, predicted_val))\n",
    "    print ('\\n confussion matrix:\\n',confusion_matrix(y_val, predicted_val))\n",
    "    \n",
    "    return predicted_test\n",
    "\n",
    "submit_lda = lda_submission(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7265700483091787\n",
      "F1 score: 0.6802259887005649\n",
      "Recall: 0.9555555555555556\n",
      "Precision: 0.5280701754385965\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.63      0.76       720\n",
      "           1       0.53      0.96      0.68       315\n",
      "\n",
      "   micro avg       0.73      0.73      0.73      1035\n",
      "   macro avg       0.75      0.79      0.72      1035\n",
      "weighted avg       0.84      0.73      0.74      1035\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[451 269]\n",
      " [ 14 301]]\n"
     ]
    }
   ],
   "source": [
    "def qda_submission(data):\n",
    "    # combine test and training data for scaling\n",
    "    train_X = data['training_data'].toarray()\n",
    "    train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "    test_X = data['test_data'].toarray()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "    clf = QuadraticDiscriminantAnalysis().fit(X_train, y_train)\n",
    "    predicted_test = clf.predict(test_X)\n",
    "    predicted_val = clf.predict(X_val)\n",
    " \n",
    "\n",
    "    print ('Accuracy:', accuracy_score(y_val, predicted_val))\n",
    "    print ('F1 score:', f1_score(y_val, predicted_val))\n",
    "    print ('Recall:', recall_score(y_val, predicted_val))\n",
    "    print ('Precision:', precision_score(y_val, predicted_val))\n",
    "    print ('\\n clasification report:\\n', classification_report(y_val, predicted_val))\n",
    "    print ('\\n confussion matrix:\\n',confusion_matrix(y_val, predicted_val))\n",
    "    \n",
    "    return predicted_test\n",
    "\n",
    "submit_qda = qda_submission(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9729468599033816\n",
      "F1 score: 0.9569230769230769\n",
      "Recall: 0.9873015873015873\n",
      "Precision: 0.9283582089552239\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       720\n",
      "           1       0.93      0.99      0.96       315\n",
      "\n",
      "   micro avg       0.97      0.97      0.97      1035\n",
      "   macro avg       0.96      0.98      0.97      1035\n",
      "weighted avg       0.97      0.97      0.97      1035\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[696  24]\n",
      " [  4 311]]\n"
     ]
    }
   ],
   "source": [
    "def xgboost_submission(data):\n",
    "    # combine test and training data for scaling\n",
    "    train_X = data['training_data'].toarray()\n",
    "    train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "    test_X = data['test_data'].toarray()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "    clf = XGBClassifier( max_depth=5,min_child_weight=1,gamma=0,subsample=0.8,colsample_bytree=0.8).fit(X_train, y_train)\n",
    "    predicted_test = clf.predict(test_X)\n",
    "    predicted_val = clf.predict(X_val)\n",
    " \n",
    "\n",
    "    print ('Accuracy:', accuracy_score(y_val, predicted_val))\n",
    "    print ('F1 score:', f1_score(y_val, predicted_val))\n",
    "    print ('Recall:', recall_score(y_val, predicted_val))\n",
    "    print ('Precision:', precision_score(y_val, predicted_val))\n",
    "    print ('\\n clasification report:\\n', classification_report(y_val, predicted_val))\n",
    "    print ('\\n confussion matrix:\\n',confusion_matrix(y_val, predicted_val))\n",
    "    \n",
    "    return predicted_test\n",
    "\n",
    "submit_xgm = xgboost_submission(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9584541062801932\n",
      "F1 score: 0.930756843800322\n",
      "Recall: 0.9174603174603174\n",
      "Precision: 0.9444444444444444\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       720\n",
      "           1       0.94      0.92      0.93       315\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1035\n",
      "   macro avg       0.95      0.95      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[703  17]\n",
      " [ 26 289]]\n",
      "Accuracy: 0.9584541062801932\n",
      "F1 score: 0.930756843800322\n",
      "Recall: 0.9174603174603174\n",
      "Precision: 0.9444444444444444\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       720\n",
      "           1       0.94      0.92      0.93       315\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1035\n",
      "   macro avg       0.95      0.95      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[703  17]\n",
      " [ 26 289]]\n"
     ]
    }
   ],
   "source": [
    "def randomforest_submission(data):\n",
    "    # combine test and training data for scaling\n",
    "    train_X = data['training_data'].toarray()\n",
    "    train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "    test_X = data['test_data'].toarray()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "    clf = RandomForestClassifier(n_estimators=100).fit(X_train, y_train)\n",
    "    \n",
    "    print ('Accuracy:', accuracy_score(y_val, predicted_val))\n",
    "    print ('F1 score:', f1_score(y_val, predicted_val))\n",
    "    print ('Recall:', recall_score(y_val, predicted_val))\n",
    "    print ('Precision:', precision_score(y_val, predicted_val))\n",
    "    print ('\\n clasification report:\\n', classification_report(y_val, predicted_val))\n",
    "    print ('\\n confussion matrix:\\n',confusion_matrix(y_val, predicted_val))\n",
    "    \n",
    "    return predicted_test\n",
    "\n",
    "submit_rf = randomforest_submission(data)\n",
    "\n",
    "\n",
    "# ### Logistic Regression\n",
    "\n",
    "# In[13]:\n",
    "\n",
    "def logreg_submission(data):\n",
    "    # combine test and training data for scaling\n",
    "    train_X = data['training_data'].toarray()\n",
    "    train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "    test_X = data['test_data'].toarray()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "    clf = LogisticRegression(C=1).fit(X_train, y_train)\n",
    "    \n",
    "    print ('Accuracy:', accuracy_score(y_val, predicted_val))\n",
    "    print ('F1 score:', f1_score(y_val, predicted_val))\n",
    "    print ('Recall:', recall_score(y_val, predicted_val))\n",
    "    print ('Precision:', precision_score(y_val, predicted_val))\n",
    "    print ('\\n clasification report:\\n', classification_report(y_val, predicted_val))\n",
    "    print ('\\n confussion matrix:\\n',confusion_matrix(y_val, predicted_val))\n",
    "    \n",
    "    return predicted_test\n",
    "\n",
    "submit_log = logreg_submission(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9584541062801932\n",
      "F1 score: 0.930756843800322\n",
      "Recall: 0.9174603174603174\n",
      "Precision: 0.9444444444444444\n",
      "\n",
      " clasification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       720\n",
      "           1       0.94      0.92      0.93       315\n",
      "\n",
      "   micro avg       0.96      0.96      0.96      1035\n",
      "   macro avg       0.95      0.95      0.95      1035\n",
      "weighted avg       0.96      0.96      0.96      1035\n",
      "\n",
      "\n",
      " confussion matrix:\n",
      " [[703  17]\n",
      " [ 26 289]]\n"
     ]
    }
   ],
   "source": [
    "def svm_submission(data, c):\n",
    "    # combine test and training data for scaling\n",
    "    train_X = data['training_data'].toarray()\n",
    "    train_y = data['training_labels'].reshape(X.shape[0],1)\n",
    "    test_X = data['test_data'].toarray()\n",
    "    X_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size=0.20, random_state=42)\n",
    "    clf = LinearSVC(C=c).fit(X_train, y_train)\n",
    "    \n",
    "    print ('Accuracy:', accuracy_score(y_val, predicted_val))\n",
    "    print ('F1 score:', f1_score(y_val, predicted_val))\n",
    "    print ('Recall:', recall_score(y_val, predicted_val))\n",
    "    print ('Precision:', precision_score(y_val, predicted_val))\n",
    "    print ('\\n clasification report:\\n', classification_report(y_val, predicted_val))\n",
    "    print ('\\n confussion matrix:\\n',confusion_matrix(y_val, predicted_val))\n",
    "    \n",
    "    return predicted_test\n",
    "submit_svm = svm_submission(data, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vote of count method for output ensemble\n",
    "from scipy import stats\n",
    "submit = [submit_log[i]+submit_rf[i]+submit_xgm[i]+submit_svm[i]+submit_ada[i] for i in range(len(submit_svm))]\n",
    "submit = np.asarray(submit)\n",
    "\n",
    "submit[np.where(submit==1)] = 0\n",
    "submit[np.where(submit==2)] = 0\n",
    "submit[np.where(submit==3)] = submit_log[np.where(submit==3)]\n",
    "submit[submit > 3] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Save as .csv\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "df = pd.DataFrame(submit)\n",
    "df.index += 1\n",
    "df['Id'] = df.index\n",
    "df.columns = ['Category', 'Id']\n",
    "df.to_csv(\"submit_new.csv\",header=True,columns=['Id','Category'],index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
